# MapReduce System with Kubernetes, Redis, and Python

Authors : Damien DASSEUX, Etienne Malacarne (SwallowedStar)

This repository contains code for a MapReduce system implemented using Kubernetes for orchestration, Redis for data storage and communication, and Python for implementing the Manager, Mapper, and Reducer components.

## Components

### Manager

The Manager component is responsible for coordinating the MapReduce process. It interacts with Redis to manage the Mapper and Reducer instances, distribute data to Mappers, collect results from Reducers, and orchestrate the overall workflow.

### Mapper

The Mapper component processes input data and generates intermediate key-value pairs. Each Mapper receives a portion of the input data, performs mapping tasks, and sends the results to the corresponding Reducer based on the key.

### Reducer

The Reducer component aggregates and processes intermediate results generated by Mappers. It receives data from multiple Mappers, performs reducing tasks, and produces the final output.

## Prerequisites

- Kubernetes cluster set up with the appropriate configurations.
- Redis deployed in the Kubernetes cluster.
- Docker installed to build and push Docker images.
- Python environment for running the Manager, Mapper, and Reducer components.

## Configuration

### Kubernetes Config

The `info932-proj.yaml` file contains the Kubernetes configurations for deploying the Manager, Mapper, Reducer, and Redis components. Make sure to customize it according to your Kubernetes cluster setup.

## Building and Deployment

1. Build Docker images for the Manager, Mapper, and Reducer components.

To do so, use the `build.bat` script. Use it like so :
```bat 
build.bat <image_version>
```
Example : 
```bat 
build.bat v1
```

2. Deploy the Manager, Mapper, and Reducer components using the Kubernetes YAML configuration with the following command:

```bash 
kubectl apply -f info932-proj.yaml
```

## Data Preparation

1. Put the input data file in the storage of the Manager component using the `kubectl cp` command. For example:

```bash 
kubectl cp <local_file_path> manager:/data/<file_name>
```

I let the file "bible.txt", so you can just do :

```bash 
kubectl cp bible.txt manager:/data/bible.txt
```


## Starting the MapReduce Process

1. Send the start signal to the Manager component using a Redis command. For example:

```bash
redis-cli -h 127.0.0.1 -p 6379 publish start <file_name>
```

If you decidedto use the bible.txt, then it will be : 

```bash
redis-cli -h 127.0.0.1 -p 6379 publish start bible.txt
```

## Getting the results

After some time, you will see the result in the Redis database with the key `final-output`. \
For example, you will be able to do :
```bash
redis-cli -h 127.0.0.1 -p 6379 HGET final-output god
```

## How it works

Here is a simplified explanation of how the MapReduce process works.

When the manager is first created, it creates a Redis Pub/Sub channel named "start". This channel is used by the user to give the manager a file to process. 

Once the signal is received, the manager will verify if there are enough Mapper and Reducer instances to process the file. If there are not enough instances, the manager will wait for the instances to be created.

Once there are enough instances, the manager will upload the file to Redis and send offsets to the Mappers. These offsets are calculated to split the file into chunks.

The mappers then do the work of mapping the data. The mappers send the results to the corresponding reducer based on a hash calculated one each word. The messages are sent through Redis Pub/Sub channels, and they are saved in the database, just in case a Reducer fails and needs to redo the work. If the file processed is big enough, then you will be able to see the saved data in the Redis database.

The reducers then do the work of reducing the data. The reducers receive the data from the mappers and aggregate them. Once it is done, the reducers save the results to the database, and send a "end" message to the manager.

The manager then adds all the results from the reducers to the final output element in the database. 

